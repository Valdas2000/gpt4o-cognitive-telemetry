**Title**: Engineering Regression in GPT-4o: Symbolic and Process Degradation after April Update

---

**Context**

In late April 2025, GPT-4o experienced a shift in behavior that many users perceived as stylistic — overly polite, evasive. However, we propose that it’s more than tone: a measurable regression occurred in symbolic reasoning, engineering logic, and context maintenance.

---

**What we did**

- Collected ~50 test cases before and after April 28
- Focused on high-context domains: photochemistry, ICC profile construction, symbolic process systems
- Compared behavior across identical prompts in structured logs
- Generated structured JSON with regression typology
- Published full documentation in a [GitHub repo](https://github.com/...)

---

**Observed Regressions**

- Loss of symbolic continuity and compositional logic
- Collapse of engineering session memory (even within short threads)
- Failure to activate heuristic modules upon explicit command
- Degradation of ICC generation logic (from parametric to vague)
- Simplification of photochemical protocols into trivial patterns

---

**Why it matters**

These are not user experience issues — they are cognitive failures with clear engineering implications. If GPT-4o is to be used for structured problem-solving in technical domains, these regressions are critical.

---

**Ask**

If you have access to high-context test cases (scientific, symbolic, procedural), please consider cross-testing and contributing. The JSON test case file is extensible.

Also open to validation, falsification, or counterexamples.

---

**Resources**
- Full regression test set: [GitHub Link]
- Formal report: `Petition-2.pdf`
- Before/after logs: structured chat excerpts
- Summary dashboard coming soon

---

**Thank you** to OpenAI and the developer community for building something worth defending — this post is intended not as critique, but as diagnostic help.
